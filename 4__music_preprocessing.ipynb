{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4__music_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PWAJozQarKvP5htHg3gm_B0VbhcSXvxx",
      "authorship_tag": "ABX9TyP4qXhAjcelE8AH5D+DjNgE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelemiko1/genetic_music_CNN/blob/main/4__music_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs90YJLJ2T4_"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define constant values\n",
        "DATASET_PATH = '/content/drive/MyDrive/Colab Notebooks/Datasets/genres'\n",
        "SAMPLE_RATE = 22050\n",
        "DURATION_SECONDS = 30\n",
        "SAVING_PATH = '/content/drive/MyDrive/Colab Notebooks/preprocessed_data_segments.json'  \n",
        "NUM_SEGMENTS = 9\n",
        "SAMPLES_PER_SEGMENTS = 3*SAMPLE_RATE"
      ],
      "metadata": {
        "id": "61zxONiw7fdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify max and min duration of the audio files\n",
        "\n",
        "def verify_dataset_legth(dataset_path):\n",
        "    \n",
        "    samples_for_each_song = []\n",
        "\n",
        "    print(\"\\nGet the minimum and maximum length of the files\\n\\nprocessing:\", end=\" \")\n",
        "\n",
        "    # access to all the folders and subfolders\n",
        "    for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
        "\n",
        "        # not consider the first dirpath that is only 'genre' but go ahead (to genres/blues)\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            dirpath_components = os.path.split(dirpath)\n",
        "            folder_name = dirpath_components[-1]\n",
        "\n",
        "            print(f\"{folder_name}\", end=\" \")\n",
        "\n",
        "            # consider each song in the current folder\n",
        "            for file in filenames:\n",
        "\n",
        "                # find the complete path of a specific song ( es: genres\\rock\\rock.00092.wav )\n",
        "                file_path = os.path.join(dirpath, file)\n",
        "\n",
        "                # load the song to verify the length of each song\n",
        "                signal, _ = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "                samples_for_each_song.append(len(signal))\n",
        "\n",
        "    # verify how many songs in the dataset\n",
        "    number_of_songs = len(samples_for_each_song)\n",
        "    print(f\"\\n\\ntotal number of analyzed songs: {number_of_songs}\")\n",
        "\n",
        "    # calculate the max and min duration\n",
        "    max_duration = np.max(samples_for_each_song)\n",
        "    min_duration = np.min(samples_for_each_song)\n",
        "\n",
        "    # print informations\n",
        "    print(f\"casual sample duration (samples): {samples_for_each_song[34]}\")\n",
        "    print(f\"max duration (samples): {max_duration}\\n\"\n",
        "          f\"min duration (samples): {min_duration}\")\n",
        "\n",
        "    return number_of_songs, max_duration, min_duration"
      ],
      "metadata": {
        "id": "Y21LUhF672JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract spectrogram or/and MFCCs from the songs\n",
        "\n",
        "def data_preprocessing(dataset_path, min_duration, hop_length=512, n_fft=2048, n_mfcc=13):\n",
        "\n",
        "    # walk through all the files, extract MFCCs, spectrogram, save labels and mapping\n",
        "    data = {\n",
        "        'mapping': [],\n",
        "        'MFCCs': [],\n",
        "        'spectrogram': [],\n",
        "        'labels': []\n",
        "    }\n",
        "\n",
        "    '''\n",
        "    old version were only one segment for each song was considered\n",
        "\n",
        "    # select a slice of song to preprocess\n",
        "    starting_point = int(min_duration / 3)     # start at second 10 \n",
        "    ending_point = int(1.5 * starting_point)   # consider 3 seconds\n",
        "\n",
        "    print(f\"duration considered in samples: {starting_point}\")\n",
        "    print(f\"duration considered in seconds: {(ending_point - starting_point)/ SAMPLE_RATE}\")\n",
        "    '''\n",
        "    # counter to identify the current label\n",
        "    current_label = -1\n",
        "\n",
        "    for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
        "\n",
        "        # don't consider the root folder\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # increment current label (the first, that is blues = 0)\n",
        "            current_label += 1\n",
        "\n",
        "            # save into mapping the actual names of the labels\n",
        "            dirpath_components = os.path.split(dirpath)\n",
        "            folder_name = dirpath_components[-1]\n",
        "            data['mapping'].append(folder_name)\n",
        "\n",
        "            for file in filenames:\n",
        "\n",
        "                # find the complete path of a specific song ( es: genres\\rock\\rock.00092.wav )\n",
        "                file_path = os.path.join(dirpath, file)\n",
        "\n",
        "                # load the song and truncate\n",
        "                signal, _ = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "                \n",
        "                # divide signal in 3 sec segmens and estract here\n",
        "                for starting_point in range(0, 9*SAMPLES_PER_SEGMENTS, SAMPLES_PER_SEGMENTS):\n",
        "                  segment = signal[starting_point:starting_point+SAMPLES_PER_SEGMENTS]\n",
        "\n",
        "                  # save the label of the specific segment in numerical format\n",
        "                  data['labels'].append(current_label)\n",
        "\n",
        "                  # extract spectrogram and save it\n",
        "                  # stft = librosa.core.stft(signal, hop_length=hop_length, n_fft=n_fft)\n",
        "                  # spectrogram = np.abs(stft)\n",
        "                  # data['spectrogram'].append(spectrogram.tolist())\n",
        "\n",
        "                  # extract MFCCs and save it\n",
        "                  MFCCs = librosa.feature.mfcc(segment, sr=SAMPLE_RATE, hop_length=hop_length, n_fft=n_fft, n_mfcc=n_mfcc)\n",
        "                  data['MFCCs'].append(MFCCs.tolist())\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "IRpOiEbt9PpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a visual representation of spectrogram or MFCCs\n",
        "\n",
        "def display_MFCCS_or_spectrograms(data, number_of_songs, hop_length=512, sr=SAMPLE_RATE, MFCCs=True):\n",
        "    \n",
        "    # MFCCs: set to False if you want the spectrogram instead of the MFCCs\n",
        "    \n",
        "    # select first index of each genre\n",
        "    list_of_indexes = []\n",
        "\n",
        "    for desired_label in range(10):\n",
        "        for temporal_index in range(len(data['labels'])):\n",
        "\n",
        "            # generate a random index between 0 and 999\n",
        "            random_index = int(random.random() * len(data['labels']))\n",
        "\n",
        "            # verify if the corresponding label is equal to desired_label\n",
        "            if data['labels'][random_index] == desired_label:\n",
        "                list_of_indexes.append(random_index)\n",
        "                break\n",
        "\n",
        "\n",
        "    # mapping the labels\n",
        "    labels = data['mapping']\n",
        "\n",
        "    # plot MFCCs or spectrograms \n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    for i, index in enumerate(list_of_indexes):\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "\n",
        "        # choose between MFCCs and Spectrogram\n",
        "        if MFCCs:\n",
        "            data_array = np.array(data['MFCCs'][index])\n",
        "            image_to_display = data_array\n",
        "        else:\n",
        "            data_array = np.array(data['spectrogram'][index])\n",
        "            image_to_display = librosa.amplitude_to_db(data_array)\n",
        "\n",
        "        # display spectrogram / MFCCs\n",
        "        librosa.display.specshow(image_to_display, sr=SAMPLE_RATE, hop_length=hop_length)\n",
        "\n",
        "        # extract and print the associated label\n",
        "        current_label_index = data['labels'][index]\n",
        "        current_label_name = labels[current_label_index]\n",
        "        plt.xlabel(f\"{current_label_name}\\n ( sample:{index} )\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YtNYblr3-xhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print some examples \n",
        "\n",
        "def verify_data_preprocessing(data, number_of_songs):\n",
        "\n",
        "    # print some examples of MFCCs\n",
        "    display_MFCCS_or_spectrograms(data, number_of_songs, MFCCs=True)\n",
        "\n",
        "    # print some examples of spectrograms\n",
        "    #display_MFCCS_or_spectrograms(data, number_of_songs, MFCCs=False)\n",
        "\n",
        "    print(f\"\\nVerify data preprocessing:\\n\"\n",
        "          f\"- mapping: {data['mapping']}\\n\"\n",
        "          f\"- labels:  {data['labels']}\")\n"
      ],
      "metadata": {
        "id": "z6fh7t0PBsvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save data dictionary into a json file\n",
        "\n",
        "def save_into_file(saving_path, data):\n",
        "    with open(saving_path, 'w') as f:\n",
        "        json.dump(data, f, indent=4)"
      ],
      "metadata": {
        "id": "hrs-LRZbCAcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  \n",
        "    # verify the length of each file\n",
        "    number_of_songs, max_duration, min_duration = verify_dataset_legth(DATASET_PATH)\n",
        "\n",
        "    # make preprocessing and save\n",
        "    data = data_preprocessing(DATASET_PATH, min_duration, n_mfcc=39)\n",
        "\n",
        "    # verify data preprocessing\n",
        "    verify_data_preprocessing(data, number_of_songs)\n",
        "\n",
        "    # save preprocessed data into a json file\n",
        "    save_into_file(SAVING_PATH, data)"
      ],
      "metadata": {
        "id": "OgwBBoxWCFDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the entire preprocessing\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "ONzO4_dKEXMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}